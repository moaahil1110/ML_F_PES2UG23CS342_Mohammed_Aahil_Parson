these are the outputs i got from changing the activation function to tanh:
Training Neural Network with your specific configuration...
Starting training...
Architecture: 1 → 72 → 32 → 1
Learning Rate: 0.005
Max Epochs: 1000, Early Stopping Patience: 10, Batch Size: 32
--------------------------------------------------
Epoch  20: Train Loss = 0.000155, Test Loss = 0.000158
Epoch  40: Train Loss = 0.000056, Test Loss = 0.000056
Epoch  60: Train Loss = 0.000028, Test Loss = 0.000027
Epoch  80: Train Loss = 0.000017, Test Loss = 0.000017
Epoch 100: Train Loss = 0.000013, Test Loss = 0.000013
Epoch 120: Train Loss = 0.000011, Test Loss = 0.000010
Epoch 140: Train Loss = 0.000010, Test Loss = 0.000010
Epoch 160: Train Loss = 0.000009, Test Loss = 0.000009
Epoch 180: Train Loss = 0.000009, Test Loss = 0.000009
Epoch 200: Train Loss = 0.000008, Test Loss = 0.000008
Epoch 220: Train Loss = 0.000008, Test Loss = 0.000008
Epoch 240: Train Loss = 0.000008, Test Loss = 0.000008
Epoch 260: Train Loss = 0.000008, Test Loss = 0.000008
Epoch 280: Train Loss = 0.000008, Test Loss = 0.000007
Epoch 300: Train Loss = 0.000007, Test Loss = 0.000007
Epoch 320: Train Loss = 0.000007, Test Loss = 0.000007
Epoch 340: Train Loss = 0.000007, Test Loss = 0.000007
Early stopping triggered at epoch 356
Best test loss: 0.000007


============================================================
PREDICTION RESULTS FOR x = 90.2
============================================================
Neural Network Prediction: 2,100,438.92
Ground Truth (formula):    2,097,167.76
Absolute Error:            3,271.16
Relative Error:            0.156%

============================================================
FINAL PERFORMANCE SUMMARY
============================================================
Final Training Loss: 0.000007
Final Test Loss:     0.000007
R² Score:           1.0000
Total Epochs Run:   356